{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Mountain-Car:-REINFORCE-Monte-Carlo-Policy-Gradients\" data-toc-modified-id=\"Mountain-Car:-REINFORCE-Monte-Carlo-Policy-Gradients-1\">Mountain Car: REINFORCE Monte Carlo Policy Gradients</a></span></li><li><span><a href=\"#This-is-a-notebook-from-Deep-Reinforcement-Learning-Course-with-Tensorflow\" data-toc-modified-id=\"This-is-a-notebook-from-Deep-Reinforcement-Learning-Course-with-Tensorflow-2\">This is a notebook from <a href=\"https://simoninithomas.github.io/Deep_reinforcement_learning_Course/\" target=\"_blank\">Deep Reinforcement Learning Course with Tensorflow</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-1:-Import-the-libraries\" data-toc-modified-id=\"Step-1:-Import-the-libraries-2.1\">Step 1: Import the libraries</a></span></li><li><span><a href=\"#Step-2:-Create-our-environment\" data-toc-modified-id=\"Step-2:-Create-our-environment-2.2\">Step 2: Create our environment</a></span></li><li><span><a href=\"#Step-3:-Set-up-our-hyperparameters\" data-toc-modified-id=\"Step-3:-Set-up-our-hyperparameters-2.3\">Step 3: Set up our hyperparameters</a></span></li><li><span><a href=\"#Step-4-:-Define-the-preprocessing-functions️\" data-toc-modified-id=\"Step-4-:-Define-the-preprocessing-functions️-2.4\">Step 4 : Define the preprocessing functions️</a></span></li><li><span><a href=\"#Step-5:-Create-our-Policy-Gradient-Neural-Network-model\" data-toc-modified-id=\"Step-5:-Create-our-Policy-Gradient-Neural-Network-model-2.5\">Step 5: Create our Policy Gradient Neural Network model</a></span></li><li><span><a href=\"#Step-6:-Set-up-Tensorboard\" data-toc-modified-id=\"Step-6:-Set-up-Tensorboard-2.6\">Step 6: Set up Tensorboard</a></span></li><li><span><a href=\"#Step-7:-Train-our-Agent\" data-toc-modified-id=\"Step-7:-Train-our-Agent-2.7\">Step 7: Train our Agent</a></span></li><li><span><a href=\"#Step-8:-Evaluate-our-trained-model\" data-toc-modified-id=\"Step-8:-Evaluate-our-trained-model-2.8\">Step 8: Evaluate our trained model</a></span></li><li><span><a href=\"#Report\" data-toc-modified-id=\"Report-2.9\">Report</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mountain Car: REINFORCE Monte Carlo Policy Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll implement an agent that plays <b> MountainCar-v0 </b>\n",
    "<video controls src=\"./assets/mountain_car.mp4\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a notebook from [Deep Reinforcement Learning Course with Tensorflow](https://simoninithomas.github.io/Deep_reinforcement_learning_Course/)\n",
    "\n",
    "The original notebook, with a solution for CartPole is [here](https://github.com/simoninithomas/Deep_reinforcement_learning_Course/blob/master/Policy%20Gradients/Cartpole/Cartpole%20REINFORCE%20Monte%20Carlo%20Policy%20Gradients.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create our environment\n",
    "This time we use <a href=\"https://gym.openai.com/\">OpenAI Gym</a> which has a lot of great environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# env_name = 'CartPole-v0'\n",
    "env_name = 'MountainCar-v0'\n",
    "# env = gym.make('MountainCar-v0')\n",
    "env = gym.make(env_name)\n",
    "env = env.unwrapped\n",
    "# Policy gradient has high variance, seed for reproducability\n",
    "env.seed(1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Set up our hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENVIRONMENT Hyperparameters\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "# print(action_size, state_size)\n",
    "## TRAINING Hyperparameters\n",
    "max_episodes = 300\n",
    "learning_rate = 0.01\n",
    "STEP_MULTIPLE = 3.0\n",
    "gamma = 0.95 # Discount rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Define the preprocessing functions️\n",
    "This function takes <b>the rewards and perform discounting.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_and_normalize_rewards(episode_rewards):\n",
    "    discounted_episode_rewards = np.zeros_like(episode_rewards)\n",
    "    cumulative = 0.0\n",
    "    for i in reversed(range(len(episode_rewards))):\n",
    "        cumulative = cumulative * gamma + episode_rewards[i]\n",
    "        discounted_episode_rewards[i] = cumulative\n",
    "    \n",
    "    mean = np.mean(discounted_episode_rewards)\n",
    "    std = np.std(discounted_episode_rewards)\n",
    "    discounted_episode_rewards = (discounted_episode_rewards - mean) / (std)\n",
    "    \n",
    "    return discounted_episode_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create our Policy Gradient Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/mountain_car.jpeg\">\n",
    "\n",
    "The idea is simple:\n",
    "- Our state which is an array of 2 values, **position** and **velocity**, which will be used as an input.\n",
    "- Our NN is 3 fully connected layers.\n",
    "- Our output activation function is **softmax** that squashes the outputs to a probability distribution:\n",
    "    - for instance: $ softmax(4,\\ 2,\\ 6) \\rightarrow (0.117,\\ 0.016,\\ 0.867) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:1\"):\n",
    "    with tf.name_scope(\"inputs\"):\n",
    "        input_ = tf.placeholder(tf.float32, [None, state_size], name=\"input_\")\n",
    "        actions = tf.placeholder(tf.int32, [None, action_size], name=\"actions\")\n",
    "        discounted_episode_rewards_ = tf.placeholder(\n",
    "            tf.float32, [None,], name=\"discounted_episode_rewards\")\n",
    "\n",
    "        # Add this placeholder for having this variable in tensorboard\n",
    "        mean_reward_ = tf.placeholder(tf.float32 , name=\"mean_reward\")\n",
    "\n",
    "        with tf.name_scope(\"fc1\"):\n",
    "            fc1 = tf.contrib.layers.fully_connected(\n",
    "                inputs = input_, num_outputs = 10,\n",
    "                activation_fn=tf.nn.relu,\n",
    "                weights_initializer=tf.contrib.layers.xavier_initializer()) \n",
    "        with tf.name_scope(\"fc2\"):\n",
    "            fc2 = tf.contrib.layers.fully_connected(\n",
    "                inputs = fc1, num_outputs = action_size,\n",
    "                activation_fn=tf.nn.relu,\n",
    "                weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        with tf.name_scope(\"fc3\"):\n",
    "            fc3 = tf.contrib.layers.fully_connected(\n",
    "                inputs = fc2, num_outputs = action_size,\n",
    "                activation_fn= None,\n",
    "                weights_initializer=tf.contrib.layers.xavier_initializer()) \n",
    "            \n",
    "        with tf.name_scope(\"softmax\"):\n",
    "            action_distribution = tf.nn.softmax(fc3)\n",
    "\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            # tf.nn.softmax_cross_entropy_with_logits computes the cross entropy \n",
    "            # of the result after applying the softmax function\n",
    "            # If you have single-class labels, where an object can only belong to one class,\n",
    "            # you might now consider using tf.nn.sparse_softmax_cross_entropy_with_logits \n",
    "            # so that you don't have to convert your labels to a dense one-hot array. \n",
    "            neg_log_prob = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                logits = fc3, labels = actions)\n",
    "            loss = tf.reduce_mean(neg_log_prob * discounted_episode_rewards_) \n",
    "\n",
    "\n",
    "        with tf.name_scope(\"train\"):\n",
    "            train_opt = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Set up Tensorboard\n",
    "For more information about tensorboard, please watch this <a href=\"https://www.youtube.com/embed/eBbEDRsCmv4\">excellent 30min tutorial</a> <br><br>\n",
    "To launch tensorboard : `tensorboard --logdir=./tensorboard/pg/1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andrew/Documents/redpanda/move_37/week_8\r\n"
     ]
    }
   ],
   "source": [
    "# Setup TensorBoard Writer\n",
    "# writer = tf.summary.FileWriter(\"/tensorboard/pg/1\")\n",
    "!rm -Rf ./tensorboard\n",
    "writer = tf.summary.FileWriter(\"./tensorboard/pg/1\")\n",
    "\n",
    "## Losses\n",
    "tf.summary.scalar(\"Loss\", loss)\n",
    "\n",
    "## Reward mean\n",
    "tf.summary.scalar(\"Reward_mean\", mean_reward_)\n",
    "\n",
    "write_op = tf.summary.merge_all()\n",
    "\n",
    "#!tensorboard --logdir=\"./tensorboard/pg/1\"\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train our Agent "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create the NN\n",
    "maxReward = 0 # Keep track of maximum reward\n",
    "For episode in range(max_episodes):\n",
    "    episode + 1\n",
    "    reset environment\n",
    "    reset stores (states, actions, rewards)\n",
    "    \n",
    "    For each step:\n",
    "        Choose action a\n",
    "        Perform action a\n",
    "        Store s, a, r\n",
    "        If done:\n",
    "            Calculate sum reward\n",
    "            Calculate gamma Gt\n",
    "            Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "allRewards = []\n",
    "total_rewards = 0\n",
    "maximumRewardRecorded = 0\n",
    "episode = 0\n",
    "episode_states, episode_actions, episode_rewards = [],[],[]\n",
    "max_reward_history = []\n",
    "step_max_history = []\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "import datetime\n",
    "import math\n",
    "from tqdm import tqdm, tnrange\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from time import strftime\n",
    "%matplotlib inline \n",
    "\n",
    "def time_delta_report(time_delta):\n",
    "    if time_delta is None:\n",
    "        time_delta = \"None\"\n",
    "    else:\n",
    "        days = time_delta.days\n",
    "        hours, remainder = divmod(time_delta.seconds, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        time_delta = f\"{days}:{str(hours).zfill(2)}:{str(minutes).zfill(2)}:{str(seconds).zfill(2)}\"\n",
    "    return time_delta\n",
    "        \n",
    "def plot_me(max_reward_history, episode, max_episodes, step_max, max_reward,\n",
    "            ep_delta, sim_delta):\n",
    "    clear_output(True)\n",
    "    fig = plt.figure(figsize=[12, 4])\n",
    "    remaining_episodes = max_episodes - episode - 1 \n",
    "   \n",
    "    if ep_delta is None:\n",
    "        eta_r = \"None\"\n",
    "    else:\n",
    "        eta_r = time_delta_report(remaining_episodes * ep_delta)\n",
    "        \n",
    "    ep_delta_r: str = time_delta_report(ep_delta)\n",
    "    sim_delta_r = time_delta_report(sim_delta)\n",
    "    remaining_episodes = max_episodes - episode - 1\n",
    "\n",
    "    fig.suptitle(f\"Episode {episode}/{max_episodes}, \"\n",
    "                 f\"Training : {sim_delta_r}  Episode : {ep_delta_r}  \"\n",
    "                 f\"ETA: {eta_r}\",\n",
    "                 fontsize=20, y=1.2)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f\"Max Reward: {max_reward}\")\n",
    "    plt.plot(max_reward_history)\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f\"Step Max: {step_max}\")\n",
    "    plt.plot(step_max_history, color=\"green\")\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "step_max = 20000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    old_position, old_velocity = None, None\n",
    "    time_delta = None\n",
    "    sim_start_time = datetime.datetime.now()\n",
    "    sim_delta = None\n",
    "    for episode in range(max_episodes):\n",
    "        plot_me(max_reward_history, episode, max_episodes, step_max, maximumRewardRecorded, time_delta, sim_delta)       \n",
    "        episode_rewards_sum = 0\n",
    "\n",
    "        # Launch the game\n",
    "        state = env.reset()\n",
    "        start_time = datetime.datetime.now()\n",
    "        \n",
    "        #env.render()\n",
    "\n",
    "        episode_max_pos, episode_min_pos = float(\"-2.0\"), float(\"2.0\")\n",
    "        direction_change_counter = 0\n",
    "        fail = False\n",
    "        str_width = int(math.log10(max_episodes)) + 1\n",
    "        str_episode = str(episode).zfill(str_width)\n",
    "\n",
    "        for counter in range(step_max):\n",
    "            # Choose action a, remember WE'RE NOT IN A DETERMINISTIC ENVIRONMENT,\n",
    "            # WE'RE OUTPUT PROBABILITIES.\n",
    "\n",
    "            action_probability_distribution = sess.run(\n",
    "                action_distribution, feed_dict={input_: state.reshape([1,state_size])})\n",
    "                # select action w.r.t the actions prob \n",
    "            action = np.random.choice(\n",
    "                range(\n",
    "                    action_probability_distribution.shape[1]),\n",
    "                    p=action_probability_distribution.ravel())\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            if old_position is None:\n",
    "                old_position, old_velocity = new_state\n",
    "            else:\n",
    "                old_position, old_velocity = position, velocity\n",
    "                \n",
    "            position, velocity = new_state\n",
    "            velocity_sign = velocity * old_velocity\n",
    "            \n",
    "            bonus = 0.0\n",
    "            if velocity_sign < 0.0:\n",
    "                new_record = False\n",
    "                direction_change_counter += 1\n",
    "                if position > episode_max_pos:\n",
    "                    episode_max_pos = position\n",
    "                    new_record = True\n",
    "                elif position < episode_min_pos:\n",
    "                    episode_min_pos = position\n",
    "                    new_record = True\n",
    "\n",
    "                if new_record:\n",
    "                    bonus = 10.0  # bonus for gaining potential energy\n",
    "                else:\n",
    "                    bonus = -2.0  # penalty for wasting potential energy\n",
    "\n",
    "            reward += bonus\n",
    "            \n",
    "            counter += 1\n",
    "            #if counter == 10:\n",
    "            #    break\n",
    "            # Store s, a, r\n",
    "            episode_states.append(state)\n",
    "                        \n",
    "            # For actions because we output only one (the index) we need 2\n",
    "            # (1 is for the action taken)\n",
    "            # We need [0., 1.] (if we take right) not just the index\n",
    "            action_ = np.zeros(action_size)\n",
    "            action_[action] = 1\n",
    "            \n",
    "            episode_actions.append(action_)\n",
    "            \n",
    "            episode_rewards.append(reward)\n",
    "           \n",
    "            if counter >= step_max:\n",
    "                # Bad Ending\n",
    "                if episode <= max_episodes:\n",
    "                    done = True\n",
    "                    fail = True\n",
    "                else:\n",
    "                    step_max = 1000000\n",
    "                    \n",
    "                \n",
    "            if done:\n",
    "\n",
    "                if counter < step_max / STEP_MULTIPLE :\n",
    "                    step_max = int(counter * STEP_MULTIPLE)\n",
    "                    \n",
    "                # Calculate sum reward\n",
    "                episode_rewards_sum = np.sum(episode_rewards)\n",
    "                \n",
    "                allRewards.append(episode_rewards_sum)\n",
    "                \n",
    "                total_rewards = np.sum(allRewards)\n",
    "                \n",
    "                # Mean reward\n",
    "                mean_reward = np.divide(total_rewards, episode+1)\n",
    "                \n",
    "                \n",
    "                maximumRewardRecorded = np.amax(allRewards)\n",
    "                max_reward_history.append(maximumRewardRecorded)\n",
    "                step_max_history.append(step_max)\n",
    "                # plot_me(max_reward_history, episode, max_episodes)\n",
    "                end_time = datetime.datetime.now()\n",
    "                time_delta = end_time - start_time\n",
    "                sim_delta = end_time - sim_start_time\n",
    "                \n",
    "                # Calculate discounted reward\n",
    "                discounted_episode_rewards = discount_and_normalize_rewards(episode_rewards)\n",
    "                                \n",
    "                # Feedforward, gradient and backpropagation\n",
    "                loss_, _ = sess.run(\n",
    "                    [loss, train_opt],\n",
    "                    feed_dict={\n",
    "                        input_: np.vstack(np.array(episode_states)),\n",
    "                        actions: np.vstack(np.array(episode_actions)),\n",
    "                        discounted_episode_rewards_: discounted_episode_rewards \n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                # Write TF Summaries\n",
    "                summary = sess.run(write_op,\n",
    "                   feed_dict={\n",
    "                       input_: np.vstack(np.array(episode_states)),\n",
    "                       actions: np.vstack(np.array(episode_actions)),\n",
    "                       discounted_episode_rewards_: discounted_episode_rewards,\n",
    "                       mean_reward_: mean_reward\n",
    "                   }\n",
    "                )\n",
    "                \n",
    "                writer.add_summary(summary, episode)\n",
    "                writer.flush()\n",
    "                \n",
    "                # Reset the transition stores\n",
    "                episode_states, episode_actions, episode_rewards = [],[],[]\n",
    "                \n",
    "                break\n",
    "            \n",
    "            state = new_state\n",
    "        \n",
    "        # Save Model\n",
    "        if episode % 100 == 0:\n",
    "            saver.save(sess, \"./models/model.ckpt\")\n",
    "            print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate our trained model\n",
    "\n",
    "Load our model and see if it generalizes well by solving 10 random games and averaging the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/model.ckpt\n",
      "****************************************************\n",
      "EPISODE  0\n",
      "Score -1018.0\n",
      "****************************************************\n",
      "EPISODE  1\n",
      "Score -738.0\n",
      "****************************************************\n",
      "EPISODE  2\n",
      "Score -540.0\n",
      "****************************************************\n",
      "EPISODE  3\n",
      "Score -1287.0\n",
      "****************************************************\n",
      "EPISODE  4\n",
      "Score -657.0\n",
      "****************************************************\n",
      "EPISODE  5\n",
      "Score -925.0\n",
      "****************************************************\n",
      "EPISODE  6\n",
      "Score -1182.0\n",
      "****************************************************\n",
      "EPISODE  7\n",
      "Score -836.0\n",
      "****************************************************\n",
      "EPISODE  8\n",
      "Score -818.0\n",
      "****************************************************\n",
      "EPISODE  9\n",
      "Score -773.0\n",
      "Score over time: -877.4\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    \n",
    "    # Load the model\n",
    "    saver.restore(sess, \"./models/model.ckpt\")\n",
    "\n",
    "    for episode in range(10):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        print(\"****************************************************\")\n",
    "        print(\"EPISODE \", episode)\n",
    "\n",
    "        while True:\n",
    "            \n",
    "\n",
    "            # Choose action a, remember WE'RE NOT IN A DETERMINISTIC ENVIRONMENT, WE'RE OUTPUT PROBABILITIES.\n",
    "            action_probability_distribution = sess.run(action_distribution, feed_dict={input_: state.reshape([1, state_size])})\n",
    "            #print(action_probability_distribution)\n",
    "            action = np.random.choice(range(action_probability_distribution.shape[1]), p=action_probability_distribution.ravel())  # select action w.r.t the actions prob\n",
    "\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                rewards.append(total_rewards)\n",
    "                print (\"Score\", total_rewards)\n",
    "                break\n",
    "            state = new_state\n",
    "    env.close()\n",
    "    print (\"Score over time: \" +  str(sum(rewards)/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "\n",
    "1.  base run with CartPole environment\n",
    "2.  changed environment to MountainCar\n",
    "3.  Changed Neural Network input to match new environment state_space dimensions\n",
    "4.  Fitness Function Experiments:\n",
    "     1. score initially improved but was stuck throughout the rest of training. Not very promising\n",
    "\t 2. Designed a new metric, **potential energy (PE)**\n",
    "         1.  Successfully improving PE during a direction change grants a bonus of +10 reward\n",
    "         2.  Failure to improve PE during a direction change provides a penalty of -2 reward\n",
    "\t 3. Added a **step limit multiplier** hyperparameter to the training that constrained training episode duration to be a multiple of our fastest training episode. Initial multiple was 1.5. \n",
    "         1.  This combined with **experiment B** definitely improved the score further during training. \n",
    "         2.  Post training evaluation results were not great.  Rewards were constantly in the negative thousands (~ -5000) \n",
    "\t 4. We found that the last set of training episodes had very short training times due to the lower step limit multiplier (1.5). To loosen this constraint, we increased the step limit multiplier from 1.5 to 3.0.\n",
    "         1.  Rewards constantly improved during training as before. \n",
    "         2.  Post training evaluation results were much better. Rewards were averaging ~-500. So this change led to an order of magnitude improvement in our evaluation testing.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:move_37]",
   "language": "python",
   "name": "conda-env-move_37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
