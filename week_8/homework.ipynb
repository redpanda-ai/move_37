{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Mountain-Car:-REINFORCE-Monte-Carlo-Policy-Gradients\" data-toc-modified-id=\"Mountain-Car:-REINFORCE-Monte-Carlo-Policy-Gradients-1\">Mountain Car: REINFORCE Monte Carlo Policy Gradients</a></span></li><li><span><a href=\"#This-is-a-notebook-from-Deep-Reinforcement-Learning-Course-with-Tensorflow\" data-toc-modified-id=\"This-is-a-notebook-from-Deep-Reinforcement-Learning-Course-with-Tensorflow-2\">This is a notebook from <a href=\"https://simoninithomas.github.io/Deep_reinforcement_learning_Course/\" target=\"_blank\">Deep Reinforcement Learning Course with Tensorflow</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-1:-Import-the-libraries\" data-toc-modified-id=\"Step-1:-Import-the-libraries-2.1\">Step 1: Import the libraries</a></span></li><li><span><a href=\"#Step-2:-Create-our-environment\" data-toc-modified-id=\"Step-2:-Create-our-environment-2.2\">Step 2: Create our environment</a></span></li><li><span><a href=\"#Step-3:-Set-up-our-hyperparameters\" data-toc-modified-id=\"Step-3:-Set-up-our-hyperparameters-2.3\">Step 3: Set up our hyperparameters</a></span></li><li><span><a href=\"#Step-4-:-Define-the-preprocessing-functions️\" data-toc-modified-id=\"Step-4-:-Define-the-preprocessing-functions️-2.4\">Step 4 : Define the preprocessing functions️</a></span></li><li><span><a href=\"#Step-5:-Create-our-Policy-Gradient-Neural-Network-model\" data-toc-modified-id=\"Step-5:-Create-our-Policy-Gradient-Neural-Network-model-2.5\">Step 5: Create our Policy Gradient Neural Network model</a></span></li><li><span><a href=\"#Step-6:-Set-up-Tensorboard\" data-toc-modified-id=\"Step-6:-Set-up-Tensorboard-2.6\">Step 6: Set up Tensorboard</a></span></li><li><span><a href=\"#Step-7:-Train-our-Agent\" data-toc-modified-id=\"Step-7:-Train-our-Agent-2.7\">Step 7: Train our Agent</a></span></li><li><span><a href=\"#Step-8:-Evaluate-our-trained-model\" data-toc-modified-id=\"Step-8:-Evaluate-our-trained-model-2.8\">Step 8: Evaluate our trained model</a></span></li><li><span><a href=\"#Report\" data-toc-modified-id=\"Report-2.9\">Report</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mountain Car: REINFORCE Monte Carlo Policy Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll implement an agent that plays <b> MountainCar-v0 </b>\n",
    "<video controls src=\"./assets/mountain_car.mp4\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a notebook from [Deep Reinforcement Learning Course with Tensorflow](https://simoninithomas.github.io/Deep_reinforcement_learning_Course/)\n",
    "\n",
    "The original notebook, with a solution for CartPole is [here](https://github.com/simoninithomas/Deep_reinforcement_learning_Course/blob/master/Policy%20Gradients/Cartpole/Cartpole%20REINFORCE%20Monte%20Carlo%20Policy%20Gradients.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create our environment\n",
    "This time we use <a href=\"https://gym.openai.com/\">OpenAI Gym</a> which has a lot of great environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# env_name = 'CartPole-v0'\n",
    "env_name = 'MountainCar-v0'\n",
    "# env = gym.make('MountainCar-v0')\n",
    "env = gym.make(env_name)\n",
    "env = env.unwrapped\n",
    "# Policy gradient has high variance, seed for reproducability\n",
    "env.seed(1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Set up our hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENVIRONMENT Hyperparameters\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "# print(action_size, state_size)\n",
    "## TRAINING Hyperparameters\n",
    "max_episodes = 300\n",
    "learning_rate = 0.01\n",
    "STEP_MULTIPLE = 4.0\n",
    "gamma = 0.95 # Discount rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Define the preprocessing functions️\n",
    "This function takes <b>the rewards and perform discounting.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_and_normalize_rewards(episode_rewards):\n",
    "    discounted_episode_rewards = np.zeros_like(episode_rewards)\n",
    "    cumulative = 0.0\n",
    "    for i in reversed(range(len(episode_rewards))):\n",
    "        cumulative = cumulative * gamma + episode_rewards[i]\n",
    "        discounted_episode_rewards[i] = cumulative\n",
    "    \n",
    "    mean = np.mean(discounted_episode_rewards)\n",
    "    std = np.std(discounted_episode_rewards)\n",
    "    discounted_episode_rewards = (discounted_episode_rewards - mean) / (std)\n",
    "    \n",
    "    return discounted_episode_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create our Policy Gradient Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/mountain_car.jpeg\">\n",
    "\n",
    "The idea is simple:\n",
    "- Our state which is an array of 2 values, **position** and **velocity**, which will be used as an input.\n",
    "- Our NN is 3 fully connected layers.\n",
    "- Our output activation function is **softmax** that squashes the outputs to a probability distribution:\n",
    "    - for instance: $ softmax(4,\\ 2,\\ 6) \\rightarrow (0.117,\\ 0.016,\\ 0.867) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:1\"):\n",
    "    with tf.name_scope(\"inputs\"):\n",
    "        input_ = tf.placeholder(tf.float32, [None, state_size], name=\"input_\")\n",
    "        actions = tf.placeholder(tf.int32, [None, action_size], name=\"actions\")\n",
    "        discounted_episode_rewards_ = tf.placeholder(\n",
    "            tf.float32, [None,], name=\"discounted_episode_rewards\")\n",
    "\n",
    "        # Add this placeholder for having this variable in tensorboard\n",
    "        mean_reward_ = tf.placeholder(tf.float32 , name=\"mean_reward\")\n",
    "\n",
    "        with tf.name_scope(\"fc1\"):\n",
    "            fc1 = tf.contrib.layers.fully_connected(\n",
    "                inputs = input_, num_outputs = 10,\n",
    "                activation_fn=tf.nn.relu,\n",
    "                weights_initializer=tf.contrib.layers.xavier_initializer()) \n",
    "        with tf.name_scope(\"fc2\"):\n",
    "            fc2 = tf.contrib.layers.fully_connected(\n",
    "                inputs = fc1, num_outputs = action_size,\n",
    "                activation_fn=tf.nn.relu,\n",
    "                weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        with tf.name_scope(\"fc3\"):\n",
    "            fc3 = tf.contrib.layers.fully_connected(\n",
    "                inputs = fc2, num_outputs = action_size,\n",
    "                activation_fn= None,\n",
    "                weights_initializer=tf.contrib.layers.xavier_initializer()) \n",
    "            \n",
    "        with tf.name_scope(\"softmax\"):\n",
    "            action_distribution = tf.nn.softmax(fc3)\n",
    "\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            # tf.nn.softmax_cross_entropy_with_logits computes the cross entropy \n",
    "            # of the result after applying the softmax function\n",
    "            # If you have single-class labels, where an object can only belong to one class,\n",
    "            # you might now consider using tf.nn.sparse_softmax_cross_entropy_with_logits \n",
    "            # so that you don't have to convert your labels to a dense one-hot array. \n",
    "            neg_log_prob = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                logits = fc3, labels = actions)\n",
    "            loss = tf.reduce_mean(neg_log_prob * discounted_episode_rewards_) \n",
    "\n",
    "\n",
    "        with tf.name_scope(\"train\"):\n",
    "            train_opt = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Set up Tensorboard\n",
    "For more information about tensorboard, please watch this <a href=\"https://www.youtube.com/embed/eBbEDRsCmv4\">excellent 30min tutorial</a> <br><br>\n",
    "To launch tensorboard : `tensorboard --logdir=./tensorboard/pg/1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andrew/Documents/redpanda/move_37/week_8\r\n"
     ]
    }
   ],
   "source": [
    "# Setup TensorBoard Writer\n",
    "# writer = tf.summary.FileWriter(\"/tensorboard/pg/1\")\n",
    "!rm -Rf ./tensorboard\n",
    "writer = tf.summary.FileWriter(\"./tensorboard/pg/1\")\n",
    "\n",
    "## Losses\n",
    "tf.summary.scalar(\"Loss\", loss)\n",
    "\n",
    "## Reward mean\n",
    "tf.summary.scalar(\"Reward_mean\", mean_reward_)\n",
    "\n",
    "write_op = tf.summary.merge_all()\n",
    "\n",
    "#!tensorboard --logdir=\"./tensorboard/pg/1\"\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train our Agent "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create the NN\n",
    "maxReward = 0 # Keep track of maximum reward\n",
    "For episode in range(max_episodes):\n",
    "    episode + 1\n",
    "    reset environment\n",
    "    reset stores (states, actions, rewards)\n",
    "    \n",
    "    For each step:\n",
    "        Choose action a\n",
    "        Perform action a\n",
    "        Store s, a, r\n",
    "        If done:\n",
    "            Calculate sum reward\n",
    "            Calculate gamma Gt\n",
    "            Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "allRewards = []\n",
    "total_rewards = 0\n",
    "maximumRewardRecorded = 0\n",
    "episode = 0\n",
    "episode_states, episode_actions, episode_rewards = [],[],[]\n",
    "max_reward_history = []\n",
    "step_max_history = []\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "import datetime\n",
    "import math\n",
    "from tqdm import tqdm, tnrange\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from time import strftime\n",
    "%matplotlib inline \n",
    "\n",
    "def time_delta_report(time_delta):\n",
    "    if time_delta is None:\n",
    "        time_delta = \"None\"\n",
    "    else:\n",
    "        days = time_delta.days\n",
    "        hours, remainder = divmod(time_delta.seconds, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        time_delta = f\"{days}:{str(hours).zfill(2)}:{str(minutes).zfill(2)}:{str(seconds).zfill(2)}\"\n",
    "    return time_delta\n",
    "        \n",
    "def plot_me(max_reward_history, episode, max_episodes, step_max, max_reward,\n",
    "            ep_delta, sim_delta):\n",
    "    clear_output(True)\n",
    "    fig = plt.figure(figsize=[12, 4])\n",
    "    remaining_episodes = max_episodes - episode - 1 \n",
    "   \n",
    "    if ep_delta is None:\n",
    "        eta_r = \"None\"\n",
    "    else:\n",
    "        eta_r = time_delta_report(remaining_episodes * ep_delta)\n",
    "        \n",
    "    ep_delta_r: str = time_delta_report(ep_delta)\n",
    "    sim_delta_r = time_delta_report(sim_delta)\n",
    "    remaining_episodes = max_episodes - episode - 1\n",
    "\n",
    "    fig.suptitle(f\"Episode {episode + 1}/{max_episodes}, \"\n",
    "                 f\"Training : {sim_delta_r}  Episode : {ep_delta_r}  \"\n",
    "                 f\"ETA: {eta_r}\",\n",
    "                 fontsize=20, y=1.2)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f\"Max Reward: {max_reward}\")\n",
    "    plt.plot(max_reward_history)\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f\"Step Max: {step_max}\")\n",
    "    plt.plot(step_max_history, color=\"green\")\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "step_max = 20000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    old_position, old_velocity = None, None\n",
    "    time_delta = None\n",
    "    sim_start_time = datetime.datetime.now()\n",
    "    sim_delta = None\n",
    "    for episode in range(max_episodes):\n",
    "        plot_me(max_reward_history, episode, max_episodes, step_max, maximumRewardRecorded, time_delta, sim_delta)       \n",
    "        episode_rewards_sum = 0\n",
    "\n",
    "        # Launch the game\n",
    "        state = env.reset()\n",
    "        start_time = datetime.datetime.now()\n",
    "        \n",
    "        #env.render()\n",
    "\n",
    "        episode_max_pos, episode_min_pos = float(\"-2.0\"), float(\"2.0\")\n",
    "        direction_change_counter = 0\n",
    "        fail = False\n",
    "        str_width = int(math.log10(max_episodes)) + 1\n",
    "        str_episode = str(episode).zfill(str_width)\n",
    "\n",
    "        for counter in range(step_max):\n",
    "            # Choose action a, remember WE'RE NOT IN A DETERMINISTIC ENVIRONMENT,\n",
    "            # WE'RE OUTPUT PROBABILITIES.\n",
    "\n",
    "            action_probability_distribution = sess.run(\n",
    "                action_distribution, feed_dict={input_: state.reshape([1,state_size])})\n",
    "                # select action w.r.t the actions prob \n",
    "            action = np.random.choice(\n",
    "                range(\n",
    "                    action_probability_distribution.shape[1]),\n",
    "                    p=action_probability_distribution.ravel())\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            if old_position is None:\n",
    "                old_position, old_velocity = new_state\n",
    "            else:\n",
    "                old_position, old_velocity = position, velocity\n",
    "                \n",
    "            position, velocity = new_state\n",
    "            velocity_sign = velocity * old_velocity\n",
    "            \n",
    "            bonus = 0.0\n",
    "            if velocity_sign < 0.0:\n",
    "                new_record = False\n",
    "                direction_change_counter += 1\n",
    "                if position > episode_max_pos:\n",
    "                    episode_max_pos = position\n",
    "                    new_record = True\n",
    "                elif position < episode_min_pos:\n",
    "                    episode_min_pos = position\n",
    "                    new_record = True\n",
    "\n",
    "                if new_record:\n",
    "                    bonus = 10.0  # bonus for gaining potential energy\n",
    "                else:\n",
    "                    bonus = -2.0  # penalty for wasting potential energy\n",
    "\n",
    "            reward += bonus\n",
    "            \n",
    "            counter += 1\n",
    "            #if counter == 10:\n",
    "            #    break\n",
    "            # Store s, a, r\n",
    "            episode_states.append(state)\n",
    "                        \n",
    "            # For actions because we output only one (the index) we need 2\n",
    "            # (1 is for the action taken)\n",
    "            # We need [0., 1.] (if we take right) not just the index\n",
    "            action_ = np.zeros(action_size)\n",
    "            action_[action] = 1\n",
    "            \n",
    "            episode_actions.append(action_)\n",
    "            \n",
    "            episode_rewards.append(reward)\n",
    "           \n",
    "            if counter >= step_max:\n",
    "                # Bad Ending\n",
    "                if episode <= max_episodes:\n",
    "                    done = True\n",
    "                    fail = True\n",
    "                else:\n",
    "                    step_max = 1000000\n",
    "                    \n",
    "                \n",
    "            if done:\n",
    "\n",
    "                if counter < step_max / STEP_MULTIPLE :\n",
    "                    step_max = int(counter * STEP_MULTIPLE)\n",
    "                    \n",
    "                # Calculate sum reward\n",
    "                episode_rewards_sum = np.sum(episode_rewards)\n",
    "                \n",
    "                allRewards.append(episode_rewards_sum)\n",
    "                \n",
    "                total_rewards = np.sum(allRewards)\n",
    "                \n",
    "                # Mean reward\n",
    "                mean_reward = np.divide(total_rewards, episode+1)\n",
    "                \n",
    "                \n",
    "                maximumRewardRecorded = np.amax(allRewards)\n",
    "                max_reward_history.append(maximumRewardRecorded)\n",
    "                step_max_history.append(step_max)\n",
    "                # plot_me(max_reward_history, episode, max_episodes)\n",
    "                end_time = datetime.datetime.now()\n",
    "                time_delta = end_time - start_time\n",
    "                sim_delta = end_time - sim_start_time\n",
    "                \n",
    "                # Calculate discounted reward\n",
    "                discounted_episode_rewards = discount_and_normalize_rewards(episode_rewards)\n",
    "                                \n",
    "                # Feedforward, gradient and backpropagation\n",
    "                loss_, _ = sess.run(\n",
    "                    [loss, train_opt],\n",
    "                    feed_dict={\n",
    "                        input_: np.vstack(np.array(episode_states)),\n",
    "                        actions: np.vstack(np.array(episode_actions)),\n",
    "                        discounted_episode_rewards_: discounted_episode_rewards \n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                # Write TF Summaries\n",
    "                summary = sess.run(write_op,\n",
    "                   feed_dict={\n",
    "                       input_: np.vstack(np.array(episode_states)),\n",
    "                       actions: np.vstack(np.array(episode_actions)),\n",
    "                       discounted_episode_rewards_: discounted_episode_rewards,\n",
    "                       mean_reward_: mean_reward\n",
    "                   }\n",
    "                )\n",
    "                \n",
    "                writer.add_summary(summary, episode)\n",
    "                writer.flush()\n",
    "                \n",
    "                # Reset the transition stores\n",
    "                episode_states, episode_actions, episode_rewards = [],[],[]\n",
    "                \n",
    "                break\n",
    "            \n",
    "            state = new_state\n",
    "        \n",
    "        # Save Model\n",
    "        if episode % 100 == 99:\n",
    "            saver.save(sess, \"./models/model.ckpt\")\n",
    "            print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate our trained model\n",
    "\n",
    "Load our model and see if it generalizes well by solving 10 random games and averaging the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/model.ckpt\n",
      "****************************************************\n",
      "EPISODE  0\n",
      "Score -778.0\n",
      "****************************************************\n",
      "EPISODE  1\n",
      "Score -467.0\n",
      "****************************************************\n",
      "EPISODE  2\n",
      "Score -666.0\n",
      "****************************************************\n",
      "EPISODE  3\n",
      "Score -846.0\n",
      "****************************************************\n",
      "EPISODE  4\n",
      "Score -1348.0\n",
      "****************************************************\n",
      "EPISODE  5\n",
      "Score -681.0\n",
      "****************************************************\n",
      "EPISODE  6\n",
      "Score -705.0\n",
      "****************************************************\n",
      "EPISODE  7\n",
      "Score -697.0\n",
      "****************************************************\n",
      "EPISODE  8\n",
      "Score -927.0\n",
      "****************************************************\n",
      "EPISODE  9\n",
      "Score -788.0\n",
      "Score over time: -790.3\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    \n",
    "    # Load the model\n",
    "    saver.restore(sess, \"./models/model.ckpt\")\n",
    "\n",
    "    for episode in range(10):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        print(\"****************************************************\")\n",
    "        print(\"EPISODE \", episode)\n",
    "\n",
    "        while True:\n",
    "            \n",
    "\n",
    "            # Choose action a, remember WE'RE NOT IN A DETERMINISTIC ENVIRONMENT, WE'RE OUTPUT PROBABILITIES.\n",
    "            action_probability_distribution = sess.run(action_distribution, feed_dict={input_: state.reshape([1, state_size])})\n",
    "            #print(action_probability_distribution)\n",
    "            action = np.random.choice(range(action_probability_distribution.shape[1]), p=action_probability_distribution.ravel())  # select action w.r.t the actions prob\n",
    "\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                rewards.append(total_rewards)\n",
    "                print (\"Score\", total_rewards)\n",
    "                break\n",
    "            state = new_state\n",
    "    env.close()\n",
    "    print (\"Score over time: \" +  str(sum(rewards)/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "\n",
    "1.  base run with CartPole environment\n",
    "2.  changed environment to MountainCar\n",
    "3.  Changed Neural Network input to match new environment state_space dimensions\n",
    "4.  Fitness Function Experiments:\n",
    "     1. score initially improved but was stuck throughout the rest of training. Not very promising\n",
    "\t 2. Designed a new metric, **potential energy (PE)**\n",
    "         1.  Successfully improving PE during a direction change grants a bonus of +10 reward\n",
    "         2.  Failure to improve PE during a direction change provides a penalty of -2 reward\n",
    "\t 3. Added a **step limit multiplier** hyperparameter to the training that constrained training episode duration to be a multiple of our fastest training episode. Initial multiple was 1.5. \n",
    "         1.  This combined with **experiment B** definitely improved the score further during training. \n",
    "         2.  Post training evaluation results were not great.  Rewards were constantly in the negative thousands (~ -5000) \n",
    "\t 4. We found that the last set of training episodes had very short training times due to the lower step limit multiplier (1.5). To loosen this constraint, we increased the step limit multiplier from 1.5 to 3.0.\n",
    "         1.  Rewards constantly improved during training as before. \n",
    "         2.  Post training evaluation results were much better. Rewards were averaging ~-500. So this change led to an order of magnitude improvement in our evaluation testing.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:move_37]",
   "language": "python",
   "name": "conda-env-move_37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
